# frozen_string_literal: true

# score setter multi-threaded
require 'rest-client'
require 'json'
require 'csv'
require 'monitor'

# These are the arguments we are expecting to get
@token = ARGV[0]
@meta_file = ARGV[1] # list of rescore rules

@enc_colon = '%3A'
@enc_dblquote = '%22'
@enc_space = '%20'

start_time = Time.now
@start_time = start_time
output_filename = "kenna_score_setter_log-#{start_time.strftime('%Y%m%dT%H%M')}.txt"
@output_filename = output_filename

# Variables we'll need later
@vuln_api_url = 'https://api.kennasecurity.com/vulnerabilities'
@vuln_api_bulk = 'bulk'
@search_url = '/search?'
@urlquerybit = 'q='
@bulk_api_url = 'https://api.kennasecurity.com/data_exports'
@headers = { 'content-type' => 'application/json', 'X-Risk-Token' => @token, 'accept' => 'application/json' }

@max_retries = 5
@debug = false

def post_data(post_url, json_data)
  # puts "posting url #{post_url}" if @debug
  # puts "posting json #{json_data}" if @debug
  query_post_return = RestClient::Request.execute(
    method: :put,
    url: post_url,
    payload: json_data,
    headers: @headers
  )
rescue RestClient::TooManyRequests => e
  retry
rescue RestClient::UnprocessableEntity => e
  puts "unprocessible entity: #{e.message}"
rescue RestClient::BadRequest => e
  log_output = File.open(@output_filename, 'a+')
  log_output << "BadRequest: #{post_url}...#{e.message} (time: #{Time.now}, start time: #{@start_time})\n"
  log_output.close
  puts "BadRequest: #{e.backtrace.inspect}"
  Thread.exit
rescue RestClient::Exception => e
  @retries ||= 0
  if @retries < @max_retries
    @retries += 1
    sleep(15)
    retry
  else
    log_output = File.open(@output_filename, 'a+')
    log_output << "General RestClient error #{post_url}... #{e.message}(time: #{Time.now}, start time: #{@start_time})\n"
    log_output.close
    puts "Unable to get vulns: #{e.backtrace.inspect}"
    Thread.exit
  end
rescue Exception => e
  log_output = File.open(@output_filename, 'a+')
  log_output << "BadRequest: #{post_url}...#{e.message} (time: #{Time.now}, start time: #{@start_time})\n"
  log_output.close
  puts "BadRequest: #{e.backtrace.inspect}"
  Thread.exit
end

# Set a finite number of simultaneous worker threads that can run
thread_count = 8

# Create an array to keep track of threads
threads = Array.new(thread_count)

# Create a work queue for the producer to give work to the consumer
work_queue = SizedQueue.new(thread_count)

# Add a monitor so we can notify when a thread finishes and we can schedule a new one
threads.extend(MonitorMixin)

# Add a condition variable on the monitored array to tell the consumer to check the thread array
threads_available = threads.new_cond

# Add a variable to tell the consumer that we are done producing work
sysexit = false

producer_thread = Thread.new do
  puts 'starting producer loop' if @debug

  ## Iterate through CSV
  CSV.foreach(@meta_file, headers: true, encoding: 'UTF-8') do |row|
    current_line = $INPUT_LINE_NUMBER

    log_output = File.open(output_filename, 'a+')
    log_output << "Reading line #{$INPUT_LINE_NUMBER}... (time: #{Time.now}, start time: #{start_time})\n"
    log_output.close

    vuln_query = ''
    cfdata = []

    unless row['Reset_Type'].nil?
      vuln_query = if row['Reset_Type'] == 'vulnerability_name'
                     "#{row['Reset_Type']}:%22#{row['Value']}%22"
                   else
                     "#{row['Reset_Type']}:#{row['Value']}"
                   end
    end
    unless row['Current_Score'].nil?
      vuln_query = "#{vuln_query}+AND+" unless vuln_query.empty?
      vuln_query = "#{vuln_query}vulnerability_score:#{row['Current_Score']}"
    end
    unless row['Tags'].nil?
      tags = row['Tags'].split(',')
      vuln_tags = if !row['Tag_Operator'].nil?
                    tags.join("\"+#{row['Tag_Operator']}+\"")
                  else
                    tags.join('"+OR+"')
                  end
      vuln_query = "#{vuln_query}+AND+" unless vuln_query.empty?
      vuln_query = "#{vuln_query}tag:(\"#{vuln_tags}\")"
    end

    unless row['Custom_Field_Name'].nil?
      cfdata = [(row['Custom_Field_Name']).to_s, (row['Custom_Field_ID']).to_s, (row['Custom_Field_Value']).to_s]
    end

    json_string = nil

    json_string = "{\"vulnerability\": {\"override_score\": #{row['New_Score']}}}"

    work_queue << Array[vuln_query, json_string, cfdata]

    # Tell the consumer to check the thread array so it can attempt to schedule the
    # next job if a free spot exists.
    threads.synchronize do
      threads_available.signal
    end
  end
  # Tell the consumer that we are finished downloading currencies
  sysexit = true
end

consumer_thread = Thread.new do
  loop do
    @retries = 0
    puts 'at start of consumer loop' if @debug

    # Stop looping when the producer is finished producing work
    work_to_do = []
    work_to_do = work_queue.pop
    break if sysexit & work_queue.nil?

    found_index = nil

    # The MonitorMixin requires us to obtain a lock on the threads array in case
    # a different thread may try to make changes to it.
    threads.synchronize do
      # First, wait on an available spot in the threads array.  This fires every
      # time a signal is sent to the "threads_available" variable
      threads_available.wait_while do
        sleep(1.0 / 2.0)
        threads.select do |thread|
          thread.nil? || thread.status == false ||
            thread['finished'].nil? == false
        end.length.zero?
      end
      # Once an available spot is found, get the index of that spot so we may
      # use it for the new thread
      found_index = threads.rindex do |thread|
        thread.nil? || thread.status == false ||
          thread['finished'].nil? == false
      end
      puts "i just found index = #{found_index}" if @debug
    end
    # Get a new unit of work from the work queue

    threads[found_index] = Thread.new(work_to_do) do
      puts 'starting the thread loop' if @debug

      vuln_query = work_to_do[0]
      json_data = work_to_do[1]
      cfdata = work_to_do[2]

      async_query = false
      query_url = nil
      pages = 0
      tot_vulns = 0
      query_response_json = nil
      query_response = nil

      query_url = "#{@vuln_api_url}#{@search_url}"
      query_url = URI.encode(query_url)

      query_url = "#{query_url}custom_fields:#{cfdata[1]}:#{cfdata[0]}%5B%5D=#{cfdata[2]}" unless cfdata.empty?

      unless vuln_query.empty?
        query_url = "#{query_url}&" unless cfdata.empty?
        query_url = "#{query_url}#{@urlquerybit}#{vuln_query}"
      end

      query_url = query_url.gsub(/&$/, '')

      puts "query url = #{query_url}" if @debug
      # puts "json data = #{json_data}" if @debug

      begin
        query_response = RestClient::Request.execute(
          method: :get,
          url: query_url,
          headers: @headers
        )

        query_meta_json = JSON.parse(query_response)['meta']
        tot_vulns = query_meta_json.fetch('total_count')
        pages = query_meta_json.fetch('pages')
        puts "first query #{query_url} tot vulns = #{tot_vulns} and pages = #{pages}"
        if tot_vulns.zero?
          Thread.kill(Thread.current)
          break
        end
      rescue RestClient::TooManyRequests => e
        retry
      rescue RestClient::UnprocessableEntity => e
        log_output = File.open(output_filename, 'a+')
        log_output << "UnprocessableEntity: #{query_url}...#{e.message} (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "UnprocessableEntity: #{e.message}"
        Thread.exit
      rescue RestClient::BadRequest => e
        log_output = File.open(output_filename, 'a+')
        log_output << "BadRequest: #{query_url}...#{e.message} (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "BadRequest: #{e.message}"
        Thread.exit
      rescue RestClient::Exception => e
        @retries ||= 0
        if @retries < @max_retries
          @retries += 1
          sleep(15)
          retry
        else
          log_output = File.open(output_filename, 'a+')
          log_output << "General RestClient error #{query_url}... #{e.message}(time: #{Time.now}, start time: #{start_time})\n"
          log_output.close
          puts "Unable to get vulns: #{e.message}"
          Thread.exit
        end
      rescue Exception => e
        log_output = File.open(output_filename, 'a+')
        log_output << "Unable to get vulns - general exception: #{e.backtrace.inspect}... (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "Unable to get vulns: #{e.message} #{e.backtrace.inspect}"
        Thread.exit
      end

      # Put the row on the work queue
      async_query = true if pages > 20
      i = 1
      vuln_ids = []
      puts "async query needed #{async_query}" if @debug

      begin
        query_url = @async_api_url.to_s if async_query

        if !async_query
          puts 'starting regular query' if @debug

          morepages = true

          while morepages
            puts "paging url = #{query_url}&page=#{i}" if @debug

            if i > 1
              query_response = RestClient::Request.execute(
                method: :get,
                url: "#{query_url}&page=#{i}",
                headers: @headers
              )
            end
            # Build URL to set the custom field value for each vulnerability
            query_response_json = JSON.parse(query_response.body)['vulnerabilities']
            meta_response_json = JSON.parse(query_response.body)['meta']
            pages = meta_response_json.fetch('pages')
            if pages == i
              morepages = false
            else
              i += 1
            end

            query_response_json.each do |item|
              vuln_ids << item['id']
            end
          end

        else
          puts 'starting async query' if @debug

          bulk_query_json_string = '{"asset": {"status": ["active"]}, "status": ["open"], '

          unless vuln_query.empty?
            temp = vuln_query.gsub('"', '\\"')
            temp = temp.gsub('+', ' ')
            bulk_query_json_string += " \"q\": \"#{temp}\","
          end
          unless cfdata.empty?
            bulk_query_json_string += "\"custom_fields:#{cfdata[1]}:#{cfdata[0]}\": [\"#{cfdata[2]}\"],"
          end
          bulk_query_json_string = "#{bulk_query_json_string}\"export_settings\": { \"format\": \"json\", "
          bulk_query_json_string = "#{bulk_query_json_string}\"compression\": \"gzip\", \"model\": \"vulnerability\" }}"

          bulk_query_json = JSON.parse(bulk_query_json_string)

          puts bulk_query_json.to_s
          query_response = RestClient::Request.execute(
            method: :post,
            url: @bulk_api_url,
            headers: @headers,
            payload: bulk_query_json_string
          )
          query_response_json = JSON.parse(query_response.body)
          searchID = query_response_json.fetch('search_id')
          puts "searchID = #{searchID}" if @debug
          # searchID = "33444"
          output_results = "myoutputfile_#{searchID}.json"
          searchComplete = false

          while searchComplete == false

            status_code = RestClient.get("https://api.kennasecurity.com/data_exports/status?search_id=#{searchID}", @headers).code

            puts "status code =#{status_code}" if @debug
            if status_code != 200
              puts 'sleeping for async query' if @debug
              sleep(60)
              next
            else
              puts 'ansyc query complete' if @debug
              searchComplete = true
              File.open(output_results, 'w') do |f|
                block = proc { |response|
                  response.read_body do |chunk|
                    f.write chunk
                  end
                }
                RestClient::Request.new(method: :get, url: "https://api.kennasecurity.com/data_exports?search_id=#{searchID}", headers: @headers, block_response: block).execute
              end
              gzfile = open(output_results)
              gz = Zlib::GzipReader.new(gzfile)
              vuln_ids = []
              results_json = JSON.parse(gz.read)['vulnerabilities']
              results_json.each do |item|
                vuln_ids << item['id']
              end

            end

          end
          File.delete(output_results)
        end

        temp_string = ''
        post_url = "#{@vuln_api_url}/#{@vuln_api_bulk}"
        puts vuln_ids.size
        count = 0

        vuln_ids.each_slice(5000) do |a|
          temp_data = nil
          puts '********* loopcount **********'
          count += 1
          puts count
          temp_data = json_data.to_s
          puts json_data
          temp_data.insert(temp_data.index('vulnerability') - 1, "\"vulnerability_ids\": #{a},")
          post_data(post_url, temp_data)
        end
      rescue RestClient::TooManyRequests => e
        retry
      rescue RestClient::UnprocessableEntity => e
        log_output = File.open(output_filename, 'a+')
        log_output << "UnprocessableEntity: #{query_url}...#{e.message} (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "UnprocessableEntity: #{e.message}"
        Thread.exit
      rescue RestClient::BadRequest => e
        log_output = File.open(output_filename, 'a+')
        log_output << "BadRequest: #{query_url}...#{e.message} (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "BadRequest: #{e.message}"
        Thread.exit
      rescue RestClient::Exception => e
        @retries ||= 0
        if @retries < @max_retries
          @retries += 1
          sleep(15)
          retry
        else
          log_output = File.open(output_filename, 'a+')
          log_output << "General RestClient error #{query_url}... #{e.message}(time: #{Time.now}, start time: #{start_time})\n"
          log_output.close
          puts "Unable to get vulns: #{e.message}"
          Thread.exit
        end
      rescue Exception => e
        log_output = File.open(output_filename, 'a+')
        log_output << "Unable to get vulns - general exception: #{e.backtrace.inspect}... (time: #{Time.now}, start time: #{start_time})\n"
        log_output.close
        puts "Unable to get vulns: #{e.message} #{e.backtrace.inspect}"
        Thread.exit
      end

      threads.synchronize do
        threads_available.signal
      end
    end
  end
end

# Join on both the producer and consumer threads so the main thread doesn't exit while
# they are doing work.
producer_thread.join
consumer_thread.join 1

# Join on the child processes to allow them to finish (if any are left)
threads.each do |thread|
  thread&.join
end
puts 'DONE!'
