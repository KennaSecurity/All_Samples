#status setter multi-threaded
require 'rest-client'
require 'cgi'
#require 'uri'
require 'json'
require 'csv'
require 'thread'
require 'monitor'

#These are the arguments we are expecting to get
@token = ARGV[0]
@meta_file = ARGV[1] #list of status change rules

start_time = Time.now
@start_time = start_time
output_filename = "kenna_status_setter_log-#{start_time.strftime("%Y%m%dT%H%M")}.txt"
@output_filename = output_filename

#Variables we'll need later
@vuln_api_url = 'https://api.kennasecurity.com/vulnerabilities'
@vuln_api_bulk = 'bulk'
@search_url = "/search?" 
@urlquerybit = 'q='
@data_exports_url = 'https://api.kennasecurity.com/data_exports'
@headers = {'content-type' => 'application/json', 'X-Risk-Token' => @token, 'accept' => 'application/json'}

@max_retries = 5
@debug = false

def post_data(post_url, json_data)
  begin
    query_post_return = RestClient::Request.execute(
      :method => :put,
      :url => post_url,
      :payload => json_data,
      :headers => @headers
    )
  rescue RestClient::TooManyRequests =>e
    retry
  rescue RestClient::UnprocessableEntity => e
    puts "unprocessible entity: #{e.message} for #{post_url}"
  rescue RestClient::BadRequest => e
    log_output = File.open(@output_filename,'a+')
    log_output << "BadRequest: #{post_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{@start_time.to_s})\n"
    log_output.close
    puts "BadRequest: #{e.backtrace.inspect}"
    Thread.exit
  rescue RestClient::Exception => e
    @retries ||= 0
    if @retries < @max_retries
      @retries += 1
      sleep(15)
      retry
    else
      log_output = File.open(@output_filename,'a+')
      log_output << "General RestClient error #{post_url}... #{e.message}(time: #{Time.now.to_s}, start time: #{@start_time.to_s})\n"
      log_output.close
      puts "Unable to get vulns: #{e.backtrace.inspect}"
      Thread.exit
    end
  rescue Exception => e
    log_output = File.open(@output_filename,'a+')
    log_output << "BadRequest: #{post_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{@start_time.to_s})\n"
    log_output.close
    puts "BadRequest: #{e.backtrace.inspect}"
    Thread.exit
    @output_filename.error("bulk vuln update status: #{JSON.parse(query_post_return.body)}... time: #{Time.now.to_s}\n")
  end
end

# Set a finite number of simultaneous worker threads that can run
thread_count = 5

# Create an array to keep track of threads
threads = Array.new(thread_count)

# Create a work queue for the producer to give work to the consumer
work_queue = SizedQueue.new(thread_count)

# Add a monitor so we can notify when a thread finishes and we can schedule a new one
threads.extend(MonitorMixin)

# Add a condition variable on the monitored array to tell the consumer to check the thread array
threads_available = threads.new_cond

# Add a variable to tell the consumer that we are done producing work
sysexit = false


producer_thread = Thread.new do
  puts "starting producer loop" if @debug
  
  ## Iterate through CSV
  CSV.foreach(@meta_file, :headers => true, :encoding => "UTF-8"){|row|

    #current_line = $.

    log_output = File.open(output_filename,'a+')
    log_output << "Reading line #{$.}... (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
    log_output.close

    vuln_query = ""
    cfdata = []

    if !row["Reset_Type"].nil? then
      if row["Reset_Type"] == "vulnerability_name" then
        vuln_query = "#{row['Reset_Type']}:%22#{row['Value']}%22"
      else
        vuln_query = "#{row['Reset_Type']}:#{row['Value']}"
      end
    end
    if !row["Tags"].nil? then
      tags = row["Tags"].split(",")
      if !row["Tag_Operator"].nil? then
        vuln_tags  =  tags.join("\"+#{row['Tag_Operator']}+\"")
      else
        vuln_tags  =  tags.join("\"+OR+\"")
      end
      if !vuln_query.empty? then
        vuln_query = "#{vuln_query}+AND+"
      end
      vuln_query = "#{vuln_query}tag:(\"#{vuln_tags}\")"
    end

    if !row["OS"].nil? then
      if !vuln_query.empty? then
        vuln_query = "#{vuln_query}+AND+"
      end
      vuln_query = "#{vuln_query}os:(\"#{row['OS']}\")"
    end

    if !row["IP"].nil? then
      if !vuln_query.empty? then
        vuln_query = "#{vuln_query}+AND+"
      end
      vuln_query = "#{vuln_query}ip:#{row['IP']}"
    end

    cfdata = ""
    
    json_string = nil

    json_string = "{\"vulnerability\": {\"status\": \"#{row['New_Status']}\""
      if !row["Set_Due_Date"].nil? then
        json_string = "#{json_string}, \"due_date\": \"#{row["Set_Due_Date"]}\""
      end
      if !row["Set_Custom_Field_Data"].nil? then 
        json_string = "#{json_string}, #{row["Set_Custom_Field_Data"]}"
      end 

     json_string = "#{json_string}}}"

    # Put the row on the work queue
    work_queue << Array[vuln_query,json_string,cfdata,row['Current_Status']]
    
    # Tell the consumer to check the thread array so it can attempt to schedule the
    # next job if a free spot exists.
    threads.synchronize do
      threads_available.signal
    end
  }
  # Tell the consumer that we are finished downloading currencies
  sysexit = true
end

consumer_thread = Thread.new do
  loop do
    @retries = 0
    puts "at start of consumer loop" if @debug

    # Stop looping when the producer is finished producing work
    work_to_do = []
    work_to_do = work_queue.pop
    break if sysexit & work_queue.nil?
    found_index = nil

    # The MonitorMixin requires us to obtain a lock on the threads array in case
    # a different thread may try to make changes to it.
    threads.synchronize do
      # First, wait on an available spot in the threads array.  This fires every
      # time a signal is sent to the "threads_available" variable
      threads_available.wait_while do
        sleep(1.0/2.0)
        threads.select { |thread| thread.nil? || thread.status == false  ||
                                  thread["finished"].nil? == false}.length == 0
      end
      # Once an available spot is found, get the index of that spot so we may
      # use it for the new thread
      found_index = threads.rindex { |thread| thread.nil? || thread.status == false ||
                                              thread["finished"].nil? == false }
      puts "i just found index = #{found_index}" if @debug
    end
    # Get a new unit of work from the work queue


    threads[found_index] = Thread.new(work_to_do) do
      puts "starting the thread loop" if @debug

      vuln_query = work_to_do[0]
      json_data = work_to_do[1]
      cfdata = work_to_do[2]
      current_status = work_to_do[3]

      async_query = false
      query_url = nil
      pages = 0
      tot_vulns = 0
      query_response_json = nil
      query_response = nil

      query_url = "#{@vuln_api_url}#{@search_url}"
      #query_url = CGI::escape(query_url)  I don't think we need to do this.
      #query_url = URI::encode(query_url)

      if !cfdata.empty? then
        query_url = "#{query_url}custom_fields:#{cfdata[1]}:#{cfdata[0]}%5B%5D=#{cfdata[2]}"
      end

      if !vuln_query.empty? then
        if !cfdata.empty? then
          query_url = "#{query_url}&"
        end
        query_url = "#{query_url}status%5B%5D=#{current_status}&#{@urlquerybit}#{vuln_query}"
      end

      query_url = query_url.gsub(/\&$/, '')

      puts "query url = #{query_url}" if @debug
      puts "json data = #{json_data}" if @debug


      begin
        query_response = RestClient::Request.execute(
          :method => :get,
          :url => query_url,
          :headers => @headers
        ) 

      query_meta_json = JSON.parse(query_response)["meta"]
      tot_vulns = query_meta_json.fetch("total_count")
      pages = query_meta_json.fetch("pages")
      puts "first query #{query_url} tot vulns = #{tot_vulns} and pages = #{pages}"
      if tot_vulns == 0 then
          Thread.kill(Thread.current)
          break
      end
      rescue RestClient::TooManyRequests => e
        retry
      rescue RestClient::UnprocessableEntity => e
        log_output = File.open(output_filename,'a+')
        log_output << "UnprocessableEntity: #{query_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "UnprocessableEntity: #{e.message}"
        Thread.exit
      rescue RestClient::BadRequest => e
        log_output = File.open(output_filename,'a+')
        log_output << "BadRequest: #{query_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "BadRequest: #{e.message}"
        Thread.exit
      rescue RestClient::Exception => e
        @retries ||= 0
        if @retries < @max_retries
          @retries += 1
          sleep(15)
          retry
        else
          log_output = File.open(output_filename,'a+')
          log_output << "General RestClient error #{query_url}... #{e.message}(time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
          log_output.close
          puts "Unable to get vulns: #{e.message}"
          Thread.exit
        end
      rescue Exception => e
        log_output = File.open(output_filename,'a+')
        log_output << "Unable to get vulns - general exception: #{e.backtrace.inspect}... (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "Unable to get vulns: #{e.message} #{e.backtrace.inspect}"
        Thread.exit
      end

      # Determine if we're going to use "Search Vulnerabilities" API or
      # an async query via data export APIs.
      if pages > 20 then
        async_query = true
      end

      i=1
      vuln_ids = []
      puts "async query needed #{async_query}" if @debug

      begin
        if !async_query then 
          puts "starting regular query" if @debug

          morepages = true

          while morepages
            puts "paging url = #{query_url}&page=#{i}" if @debug

            if i>1 then
              query_response = RestClient::Request.execute(
                :method => :get,
                :url => "#{query_url}&page=#{i}",
                :headers => @headers
              )
            end
            # Build URL to set the custom field value for each vulnerability
            query_response_json = JSON.parse(query_response.body)["vulnerabilities"]
            meta_response_json = JSON.parse(query_response.body)["meta"]
            pages = meta_response_json.fetch("pages")
            if pages == i then
              morepages = false
            else
              i+=1
            end

            query_response_json.each do |item|
              vuln_ids << item["id"]
            end
          end

        else
          puts "starting async query (data export)" if @debug

          bulk_query_json_string = "{\"asset\": {\"status\": [\"active\"]}, \"status\": [\"#{current_status}\"], "

          if !vuln_query.empty? then
            temp = vuln_query.gsub('"','\\"')
            temp = temp.gsub("+"," ")
            bulk_query_json_string = bulk_query_json_string + " \"q\": \"#{temp}\","  
          end
          if !cfdata.empty? then
            bulk_query_json_string = bulk_query_json_string + "\"custom_fields:#{cfdata[1]}:#{cfdata[0]}\": [\"#{cfdata[2]}\"],"
          end
          bulk_query_json_string = bulk_query_json_string + "\"export_settings\": { \"format\": \"json\", "
          bulk_query_json_string = bulk_query_json_string + "\"compression\": \"gzip\", \"model\": \"vulnerability\" }}"

          puts "bulk query (Request Data Exports) ***** " + bulk_query_json_string
   
          query_response = RestClient::Request.execute(
            :method => :post,
            :url => @data_exports_url,
            :headers => @headers,
            :payload => bulk_query_json_string
          ) 
          query_response_json = JSON.parse(query_response.body)
          searchID = query_response_json.fetch("search_id")
          puts "searchID = #{searchID}" if @debug
          #searchID = "33444"
          output_results = "myoutputfile_#{searchID}.gz"
          searchComplete = false

          # Check status for completion of data export.
          while searchComplete == false
          
            status_code = RestClient.get("https://api.kennasecurity.com/data_exports/status?search_id=#{searchID}", @headers).code

            puts "status code =#{status_code}" if @debug
            if status_code != 200 then 
              puts "sleeping for async query" if @debug
              sleep(60)
              next
            else
              puts "ansyc query (data export) complete" if @debug
              searchComplete = true

              # Download the gzip file.
              File.open(output_results, 'w') {|f|
                block = proc { |response|
                  response.read_body do |chunk| 
                    f.write chunk
                  end
                }
                RestClient::Request.new(:method => :get, :url => "https://api.kennasecurity.com/data_exports?search_id=#{searchID}", :headers => @headers, :block_response => block).execute
              }
              
              # Open gzip file and process.
              gzfile = open(output_results)
              gz = Zlib::GzipReader.new(gzfile)
              vuln_ids = []
              results_json = JSON.parse(gz.read)["vulnerabilities"]
              results_json.each do |item|
                vuln_ids << item["id"]
              end
             
            end 
               
          end
          File.delete(output_results)
        end

        post_url = "#{@vuln_api_url}/#{@vuln_api_bulk}"
        puts vuln_ids.size
        count = 0

        vuln_ids.each_slice(5000) do |a|
          temp_data = nil
          puts "********* loopcount **********"
          count+=1
          puts count
          #json_data = json_data.gsub('"','\\"')
          #json_data = json_data.gsub("+"," ")
          temp_data = "#{json_data}"
          puts json_data
          temp_data = temp_data.insert(temp_data.index('vulnerability')-1, "\"vulnerability_ids\": #{a},") 
          puts temp_data
          post_data(post_url, temp_data)

        end 

      rescue RestClient::TooManyRequests => e
        retry
      rescue RestClient::UnprocessableEntity => e
        log_output = File.open(output_filename,'a+')
        log_output << "UnprocessableEntity: #{query_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "UnprocessableEntity: #{e.message} for #{query_url}"
        Thread.exit
      rescue RestClient::BadRequest => e
        log_output = File.open(output_filename,'a+')
        log_output << "BadRequest: #{query_url}...#{e.message} (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "BadRequest: #{e.message}"
        Thread.exit
      rescue RestClient::Exception => e
        @retries ||= 0
        if @retries < @max_retries
          @retries += 1
          sleep(15)
          retry
        else
          log_output = File.open(output_filename,'a+')
          log_output << "General RestClient error #{query_url}... #{e.message}(time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
          log_output.close
          puts "Unable to get vulns: #{e.message}"
          Thread.exit
        end
      rescue Exception => e
        log_output = File.open(output_filename,'a+')
        log_output << "Unable to get vulns - general exception: #{e.backtrace.inspect}... (time: #{Time.now.to_s}, start time: #{start_time.to_s})\n"
        log_output.close
        puts "Unable to get vulns: #{e.message} #{e.backtrace.inspect}"
        Thread.exit
      end

      threads.synchronize do
        threads_available.signal
      end
    end
  end 
end

# Join on both the producer and consumer threads so the main thread doesn't exit while
# they are doing work.
producer_thread.join
consumer_thread.join 1

# Join on the child processes to allow them to finish (if any are left)
threads.each do |thread|
    thread.join unless thread.nil?
end
puts "DONE!"

